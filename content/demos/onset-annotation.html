<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="ARME Web Demo.">
  <meta name="keywords" content="ARME, Onset Annotation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ARME: Onset Annotation</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id="></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.ico">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://arme-project.co.uk/demos/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://arme-project.co.uk/">
            ARME Project
          </a>
          <a class="navbar-item" href="https://arme-project.co.uk/demos/sqd">
            String quartet dataset (ARME-SQD)
          </a>          
          <a class="navbar-item" href="https://arme-project.co.uk/publication/synchronisation-in-a-virtual-quartet/">
            Synchronisation in a virtual quartet
          </a>
          <a class="navbar-item" href="https://arme-project.co.uk/publication/synchronisation-in-a-violin-duo/">
            Synchronisation with a violin duo
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Annotation of Soft Onsets in String Ensemble Recordings</h1>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://arme-project.co.uk/people/">Maciek Tomczak</a><sup>a</sup>,</span>
            <span class="author-block">
              <a href="https://arme-project.co.uk/people/">Min Susan Lee</a><sup>b</sup>,</span>
            <span class="author-block">
              <a href="https://arme-project.co.uk/people/">Adrian Bradbury</a><sup>b</sup>,
            </span>
            <span class="author-block">
              <a href="https://arme-project.co.uk/people/">Mark Elliott</a><sup>c</sup>,
            </span>
            <span class="author-block">
              <a href="https://arme-project.co.uk/people/">Ryan Stables</a><sup>a</sup>,
            </span>
            <span class="author-block">
              <a href="https://arme-project.co.uk/people/">Maria Witek</a><sup>b</sup>,
            </span>
            <span class="author-block">
              <a href="https://arme-project.co.uk/people/">Tom Goodman</a><sup>b</sup>,
            </span>
            <span class="author-block">
              <a href="https://arme-project.co.uk/people/">Diar Abdlkarim</a><sup>b</sup>,
            </span>            
            <span class="author-block">
              <a href="https://arme-project.co.uk/people/">Max Di Luca</a><sup>b</sup>,
            </span>
            <span class="author-block">
              <a href="https://arme-project.co.uk/people/">Alan Wing</a><sup>b</sup>,
            </span>
            <span class="author-block">
              <a href="https://arme-project.co.uk/people/">Jason Hockman</a><sup>a</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>a</sup>Birmingham City University, <a href="https://somagroup.co.uk/">Sound and Music Analysis (SoMA) Group</a>, Birmingham, UK</span>
              <br>
            <span class="author-block"><sup>b</sup>University of Birmingham, Sensory Motor Neuroscience (SyMon) Centre, Birmingham, UK</span>
            <br>
            <span class="author-block"><sup>c</sup>WMG, University of Warwick, Coventry, UK</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/arme-project/haydn-annotation-dataset" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Annotations</span>
                </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/arme-project/virtuoso-strings" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Audio</span>
                </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="./onset-annotation-of-string-ensembles/results/results_October_2022.zip" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fa fa-image"></i>
                  </span>
                  <span>Results</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Supplementary experimental results for the paper <a href="https://github.com/arme-project/haydn-annotation-dataset">Annotation of Soft Onsets in String Ensemble Recordings</a>. 
          </p>
          <p>
            Onset detection is the process of identifying the start points of musical note events within an audio recording. 
            While the detection of percussive onsets is often considered a solved problem, soft onsets&#8212as found in string instrument recordings&#8212still pose a significant challenge for state-of-the-art algorithms. 
            The problem is further exacerbated by a paucity of data containing expert annotations and research related to best practices for curating soft onset annotations for string instruments. 
            To this end, we investigate inter-annotator agreement between 24 participants, extend an algorithm for determining the most consistent annotator, and compare the performance of human annotators and state-of-the-art onset detection algorithms. 
            Experimental results reveal a positive trend between musical experience and both inter-annotator agreement and performance in comparison with automated systems. 
            Additionally, onsets produced by changes in fingering as well as those from the cello were found to be particularly challenging for both human annotators and automatic approaches. 
            To promote research in best practices for annotation of soft onsets, we have made all experimental data associated with this study publicly available. 
            In addition, we also publish the <a href="https://github.com/arme-project/virtuoso-strings">ARME Virtuoso Strings Dataset</a>, consisting of over 144 recordings of professional performances of an excerpt from Haydn's Op. 74 No. 1 Finale, <a href="https://github.com/arme-project/haydn-annotation-dataset">each with corresponding individual instrumental note onset annotations</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">BibTeX</h2>
        <div class="content has-text-justified">
          <p>If you use the resources on this website in your research, feel free to cite this paper:</p>
          <pre>
            <code>
              @
            </code>
          </pre>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3">Musical Conditions</h2>
        
    <p>The musical conditions used in our study represent different playing styles and were chosen to span a wide range of performance types. The following are definitions of the three analysed conditions.</p>
    <br>
    <ul>
      <li><b>Normal condition (NR)</b> represents a concert style performance.</li>
      <li><b>Speed condition (SP)</b> includes accelerando and decelerando spontaneously initiated by a single musician (i.e., the leader) throughout each performance.</li>
      <li><b>Deadpan condition (DP)</b> represents performances, where musicians were asked to play with minimal expression in tempo and accentuation.</li>
    </ul>

    <br>
    <p>For additional information please refer to the <a href="https://github.com/arme-project/haydn-annotation-dataset">paper</a>.</p>

  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">

    <!-- Animation all participants. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Inter-annotator Agreements for All Participants</h2>
        <p>Inter-annotator agreement results for the 12th repetition of the NR condition recordings (NR12) visualised over different tolerance windows (20-100 ms) for viola, cello, and first and second violin (VA, VC, VN1 and V2). For more details please refer to Experiment 1 in the <a href="https://github.com/arme-project/haydn-annotation-dataset">paper</a>.</p>
        <br><br>

        <!-- Interpolating Viola. -->
        <h3 class="title is-4">Viola - 24 Annotators</h3>
        <div class="content has-text-justified">
          <p>
            Pairwise agreements between 24 annotators using F-measure score sorted by years of musical experience.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="onset-annotation-of-string-ensembles/all/VA/000000.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>20ms Tolerance Window</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper-va">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider-va"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="onset-annotation-of-string-ensembles/all/VA/000010.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">70ms Tolerance Window</p>
          </div>
        </div>
        <br/>
        <!--/ Interpolating. -->

        <!-- Interpolating Cello. -->
        <h3 class="title is-4">Cello - 24 Annotators</h3>
        <div class="content has-text-justified">
          <p>
            Pairwise agreements between 24 annotators using F-measure score sorted by years of musical experience.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="onset-annotation-of-string-ensembles/all/VC/000000.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>20ms Tolerance Window</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper-vc">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider-vc"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="onset-annotation-of-string-ensembles/all/VC/000010.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">70ms Tolerance Window</p>
          </div>
        </div>
        <br/>
        <!--/ Interpolating. -->        

        <!-- Interpolating First Violin. -->
        <h3 class="title is-4">First Violin - 24 Annotators</h3>
        <div class="content has-text-justified">
          <p>
            Pairwise agreements between 24 annotators using F-measure score sorted by years of musical experience.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="onset-annotation-of-string-ensembles/all/VN1/000000.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>20ms Tolerance Window</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper-vn1">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider-vn1"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="onset-annotation-of-string-ensembles/all/VN1/000010.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">70ms Tolerance Window</p>
          </div>
        </div>
        <br/>
        <!--/ Interpolating. -->     

        <!-- Interpolating Second Violin. -->
        <h3 class="title is-4">Second Violin - 24 Annotators</h3>
        <div class="content has-text-justified">
          <p>
            Pairwise agreements between 24 annotators using F-measure score sorted by years of musical experience.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="onset-annotation-of-string-ensembles/all/VN2/000000.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>20ms Tolerance Window</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper-vn2">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider-vn2"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="onset-annotation-of-string-ensembles/all/VN2/000010.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">70ms Tolerance Window</p>
          </div>
        </div>
        <br/>
        <!--/ Interpolating. -->   
        
        
    <!-- Animation 16 participants. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Inter-annotator Agreements for a Subset of Participants</h2>

        <!-- Interpolating Viola. -->
        <h3 class="title is-4">Viola - 16 Annotators</h3>
        <div class="content has-text-justified">
          <p>
            Pairwise F-measure agreements between 16 annotators with 5 or more years of musical experience.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="onset-annotation-of-string-ensembles/16_participants/VA/000000.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>20ms Tolerance Window</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper-va-16">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider-va-16"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="onset-annotation-of-string-ensembles/16_participants/VA/000010.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">70ms Tolerance Window</p>
          </div>
        </div>
        <br/>
        <!--/ Interpolating. -->

        <!-- Interpolating Cello. -->
        <h3 class="title is-4">Cello - 16 Annotators</h3>
        <div class="content has-text-justified">
          <p>
            Pairwise F-measure agreements between 16 annotators with 5 or more years of musical experience.          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="onset-annotation-of-string-ensembles/16_participants/VC/000000.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>20ms Tolerance Window</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper-vc-16">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider-vc-16"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="onset-annotation-of-string-ensembles/16_participants/VC/000010.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">70ms Tolerance Window</p>
          </div>
        </div>
        <br/>
        <!--/ Interpolating. -->        

        <!-- Interpolating First Violin. -->
        <h3 class="title is-4">First Violin - 16 Annotators</h3>
        <div class="content has-text-justified">
          <p>
            Pairwise F-measure agreements between 16 annotators with 5 or more years of musical experience.          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="onset-annotation-of-string-ensembles/16_participants/VN1/000000.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>20ms Tolerance Window</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper-vn1-16">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider-vn1-16"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="onset-annotation-of-string-ensembles/16_participants/VN1/000010.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">70ms Tolerance Window</p>
          </div>
        </div>
        <br/>
        <!--/ Interpolating. -->     

        <!-- Interpolating Second Violin. -->
        <h3 class="title is-4">Second Violin - 16 Annotators</h3>
        <div class="content has-text-justified">
          <p>
            Pairwise agreements between 24 annotators using F-measure score sorted by years of musical experience.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="onset-annotation-of-string-ensembles/16_participants/VN2/000000.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>20ms Tolerance Window</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper-vn2-16">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider-vn2-16"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="onset-annotation-of-string-ensembles/16_participants/VN2/000010.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">70ms Tolerance Window</p>
          </div>
        </div>
        <br/>
        <!--/ Interpolating. -->     

      </div>
    </div>
    <!--/ Animation. -->

    <section class="section">
      <div class="container is-max-desktop">
        <div class="content has-text-justified">
        <h2 class="title is-3">Inter-annotator Performance</h2>
        <p>For more details please refer to Experiment 2 in the <a href="https://github.com/arme-project/haydn-annotation-dataset">paper</a>.</p>
        
        <img src="onset-annotation-of-string-ensembles/JNMR2022_results/annotators-performance-against-expert.png" class="interpolation-image"
          alt="Onset detection results from CNN system." />
          
            <p>Figure 1. True positive rates per participant compared to ground truth expert annotations a_0 in NR12.</p>
            <br>
            <p>Figure 1 shows the performance of each annotator a calculated as percentage of TP onsets per instrument and onset category when compared to the expert annotations a_0 (i.e., here considered ground truth). The reported results use tolerance window size of 25 ms and are presented for every annotation participant. 
              The highest mean accuracy of 98%, 97%, and 96% across onset types and instruments is observed in annotators a_2, a_20 and a_23, respectively. 
              The lowest mean performance across onset types and instruments can be seen in annotators a_9, a_7 and a_16 with respective true positive rates of 12.8%, 42.5% and 55.2%. 
              Additionally, means across onset types and annotators are 82.0%, 72.4%, 82.8% and 81.7% for VA, VC, VN1 and VN2, respectively. </p>
        <h2 class="title is-3">Onset Detection Results For Each Instrument</h2>
        <p>For more details please refer to Experiment 3 in the <a href="https://github.com/arme-project/haydn-annotation-dataset">paper</a>.</p>
        
        <img src="onset-annotation-of-string-ensembles/JNMR2022_results/ons-det-instrument-systems-conditions.png" class="interpolation-image"
          alt="Onset detection results from all systems per instrument." />
          <p>Figure 2. Onset detection results as a correspondence between the onsets detected by the algorithms and compared against annotations from the annotators a_0, a_12, a_13, a_16, a_18.</p>
          <br>
          <p>Results are reported for five algorithms using annotations from NR, SP and DP conditions as well as, expert annotations a_0 from NR12. 
            The overall highest performing algorithms for all instruments are CNN and CoF. 
            The highest precision is achieved by CNN system (0.93) on the VN1 recordings with NR12 expert annotations. 
            In the NR, SP and DP conditions the highest precision is achieved by the CNN (0.8), CoF (0.8), and CNN (0.83) algorithms in VN1, VN2 and VN1 instruments, respectively. </p>
    
        <h2 class="title is-3">Onset Detection Results For Each Participant</h2>
        <p>For more details please refer to Experiment 3 in the <a href="https://github.com/arme-project/haydn-annotation-dataset">paper</a>.</p>

        <img src="onset-annotation-of-string-ensembles/JNMR2022_results/ons-det-cnn-means.png" class="interpolation-image"
        alt="Onset detection results from CNN system." />
        <p>Figure 3. Mean F-measure, precision and recall for CNN method calculated for each annotator and instrument.</p>
          
        <p>Figure 3 extends the per-instrument means plotted in <a href="https://github.com/arme-project/haydn-annotation-dataset">Figure 7 in the paper</a>.</p>

        </div>
      </div>
    </section>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons 
              Attribution-ShareAlike 4.0 International License</a> with source code available <a href="https://github.com/nerfies/nerfies.github.io">here</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
